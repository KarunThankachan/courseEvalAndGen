{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Script_Fine_Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqohQc8t-Q33",
        "colab_type": "code",
        "outputId": "72d02f99-498f-47fb-a6bb-b9b13faf2984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        }
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-arl7jhp0\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-arl7jhp0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.2)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.12.40)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.38.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 29.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 37.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.15.40)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers==2.8.0) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers==2.8.0) (0.15.2)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.8.0-cp36-none-any.whl size=585132 sha256=9fe3410e876117218aea310baed72a1ca65d5388321215fe223aeded876ce9ff\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-txlb9by6/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=28fe01e76568e3fd50d457ecf114c041f9e2797b2e4f784d43f1919b331e8a99\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.85 tokenizers-0.7.0 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdSW7kHNQdsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDwnRbI9-nrT",
        "colab_type": "code",
        "outputId": "fd6cbf93-4374-46eb-cf3f-c98fbb06e9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_language_modeling.py \\\n",
        "    --output_dir=output \\\n",
        "    --model_type=bert \\\n",
        "    --model_name_or_path=bert-base-uncased \\\n",
        "    --do_train \\\n",
        "    --train_data_file=train_data.raw \\\n",
        "    --do_eval \\\n",
        "    --per_gpu_train_batch_size 4 \\\n",
        "    --eval_data_file=test_data.raw \\\n",
        "    --mlm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-24 13:16:58.140798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "04/24/2020 13:16:59 - INFO - transformers.training_args -   PyTorch: setting up devices\n",
            "04/24/2020 13:16:59 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "04/24/2020 13:16:59 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='output', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_gpu_train_batch_size=4, per_gpu_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir=None, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1)\n",
            "04/24/2020 13:16:59 - INFO - filelock -   Lock 140433441834040 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685.lock\n",
            "04/24/2020 13:16:59 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpg32hefzp\n",
            "Downloading: 100% 361/361 [00:00<00:00, 455kB/s]\n",
            "04/24/2020 13:16:59 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
            "04/24/2020 13:16:59 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
            "04/24/2020 13:16:59 - INFO - filelock -   Lock 140433441834040 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685.lock\n",
            "04/24/2020 13:16:59 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
            "04/24/2020 13:16:59 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/24/2020 13:17:00 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
            "04/24/2020 13:17:00 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/24/2020 13:17:00 - INFO - filelock -   Lock 140433060604448 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "04/24/2020 13:17:00 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp8x2spk2n\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 4.44MB/s]\n",
            "04/24/2020 13:17:00 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/24/2020 13:17:00 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/24/2020 13:17:00 - INFO - filelock -   Lock 140433060604448 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "04/24/2020 13:17:00 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/24/2020 13:17:00 - INFO - filelock -   Lock 140432930481656 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "04/24/2020 13:17:00 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp4cu6ltx1\n",
            "Downloading: 100% 440M/440M [00:05<00:00, 81.2MB/s]\n",
            "04/24/2020 13:17:06 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "04/24/2020 13:17:06 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "04/24/2020 13:17:06 - INFO - filelock -   Lock 140432930481656 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "04/24/2020 13:17:06 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "04/24/2020 13:17:09 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
            "04/24/2020 13:17:09 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "04/24/2020 13:17:09 - INFO - transformers.data.datasets.language_modeling -   Creating features from dataset file at \n",
            "04/24/2020 13:17:11 - INFO - transformers.data.datasets.language_modeling -   Saving features into cached file cached_lm_BertTokenizer_510_train_data.raw [took 0.004 s]\n",
            "04/24/2020 13:17:11 - INFO - transformers.data.datasets.language_modeling -   Creating features from dataset file at \n",
            "04/24/2020 13:17:12 - INFO - transformers.data.datasets.language_modeling -   Saving features into cached file cached_lm_BertTokenizer_510_test_data.raw [took 0.001 s]\n",
            "04/24/2020 13:17:27 - INFO - transformers.trainer -   ***** Running training *****\n",
            "04/24/2020 13:17:27 - INFO - transformers.trainer -     Num examples = 361\n",
            "04/24/2020 13:17:27 - INFO - transformers.trainer -     Num Epochs = 3\n",
            "04/24/2020 13:17:27 - INFO - transformers.trainer -     Instantaneous batch size per GPU = 4\n",
            "04/24/2020 13:17:27 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "04/24/2020 13:17:27 - INFO - transformers.trainer -     Gradient Accumulation steps = 1\n",
            "04/24/2020 13:17:27 - INFO - transformers.trainer -     Total optimization steps = 273\n",
            "Epoch:   0% 0/3 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/91 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/91 [00:00<00:57,  1.56it/s]\u001b[A\n",
            "Iteration:   2% 2/91 [00:00<00:47,  1.86it/s]\u001b[A\n",
            "Iteration:   3% 3/91 [00:01<00:41,  2.14it/s]\u001b[A\n",
            "Iteration:   4% 4/91 [00:01<00:36,  2.39it/s]\u001b[A\n",
            "Iteration:   5% 5/91 [00:01<00:32,  2.61it/s]\u001b[A\n",
            "Iteration:   7% 6/91 [00:02<00:30,  2.79it/s]\u001b[A\n",
            "Iteration:   8% 7/91 [00:02<00:28,  2.94it/s]\u001b[A\n",
            "Iteration:   9% 8/91 [00:02<00:27,  3.05it/s]\u001b[A\n",
            "Iteration:  10% 9/91 [00:03<00:26,  3.13it/s]\u001b[A\n",
            "Iteration:  11% 10/91 [00:03<00:25,  3.17it/s]\u001b[A\n",
            "Iteration:  12% 11/91 [00:03<00:24,  3.21it/s]\u001b[A\n",
            "Iteration:  13% 12/91 [00:03<00:24,  3.24it/s]\u001b[A\n",
            "Iteration:  14% 13/91 [00:04<00:23,  3.27it/s]\u001b[A\n",
            "Iteration:  15% 14/91 [00:04<00:23,  3.30it/s]\u001b[A\n",
            "Iteration:  16% 15/91 [00:04<00:22,  3.31it/s]\u001b[A\n",
            "Iteration:  18% 16/91 [00:05<00:22,  3.31it/s]\u001b[A\n",
            "Iteration:  19% 17/91 [00:05<00:22,  3.31it/s]\u001b[A\n",
            "Iteration:  20% 18/91 [00:05<00:22,  3.32it/s]\u001b[A\n",
            "Iteration:  21% 19/91 [00:06<00:21,  3.32it/s]\u001b[A\n",
            "Iteration:  22% 20/91 [00:06<00:21,  3.33it/s]\u001b[A\n",
            "Iteration:  23% 21/91 [00:06<00:20,  3.34it/s]\u001b[A\n",
            "Iteration:  24% 22/91 [00:06<00:20,  3.34it/s]\u001b[A\n",
            "Iteration:  25% 23/91 [00:07<00:20,  3.34it/s]\u001b[A\n",
            "Iteration:  26% 24/91 [00:07<00:19,  3.35it/s]\u001b[A\n",
            "Iteration:  27% 25/91 [00:07<00:19,  3.34it/s]\u001b[A\n",
            "Iteration:  29% 26/91 [00:08<00:19,  3.35it/s]\u001b[A\n",
            "Iteration:  30% 27/91 [00:08<00:19,  3.33it/s]\u001b[A\n",
            "Iteration:  31% 28/91 [00:08<00:18,  3.32it/s]\u001b[A\n",
            "Iteration:  32% 29/91 [00:09<00:18,  3.33it/s]\u001b[A\n",
            "Iteration:  33% 30/91 [00:09<00:18,  3.34it/s]\u001b[A\n",
            "Iteration:  34% 31/91 [00:09<00:17,  3.35it/s]\u001b[A\n",
            "Iteration:  35% 32/91 [00:09<00:17,  3.36it/s]\u001b[A\n",
            "Iteration:  36% 33/91 [00:10<00:17,  3.37it/s]\u001b[A\n",
            "Iteration:  37% 34/91 [00:10<00:16,  3.38it/s]\u001b[A\n",
            "Iteration:  38% 35/91 [00:10<00:16,  3.38it/s]\u001b[A\n",
            "Iteration:  40% 36/91 [00:11<00:16,  3.37it/s]\u001b[A\n",
            "Iteration:  41% 37/91 [00:11<00:15,  3.38it/s]\u001b[A\n",
            "Iteration:  42% 38/91 [00:11<00:15,  3.37it/s]\u001b[A\n",
            "Iteration:  43% 39/91 [00:12<00:15,  3.36it/s]\u001b[A\n",
            "Iteration:  44% 40/91 [00:12<00:15,  3.35it/s]\u001b[A\n",
            "Iteration:  45% 41/91 [00:12<00:14,  3.35it/s]\u001b[A\n",
            "Iteration:  46% 42/91 [00:12<00:14,  3.35it/s]\u001b[A\n",
            "Iteration:  47% 43/91 [00:13<00:14,  3.35it/s]\u001b[A\n",
            "Iteration:  48% 44/91 [00:13<00:14,  3.35it/s]\u001b[A\n",
            "Iteration:  49% 45/91 [00:13<00:13,  3.34it/s]\u001b[A\n",
            "Iteration:  51% 46/91 [00:14<00:13,  3.34it/s]\u001b[A\n",
            "Iteration:  52% 47/91 [00:14<00:13,  3.33it/s]\u001b[A\n",
            "Iteration:  53% 48/91 [00:14<00:12,  3.32it/s]\u001b[A\n",
            "Iteration:  54% 49/91 [00:15<00:12,  3.33it/s]\u001b[A\n",
            "Iteration:  55% 50/91 [00:15<00:12,  3.33it/s]\u001b[A\n",
            "Iteration:  56% 51/91 [00:15<00:12,  3.29it/s]\u001b[A\n",
            "Iteration:  57% 52/91 [00:15<00:11,  3.30it/s]\u001b[A\n",
            "Iteration:  58% 53/91 [00:16<00:11,  3.30it/s]\u001b[A\n",
            "Iteration:  59% 54/91 [00:16<00:11,  3.31it/s]\u001b[A\n",
            "Iteration:  60% 55/91 [00:16<00:10,  3.32it/s]\u001b[A\n",
            "Iteration:  62% 56/91 [00:17<00:10,  3.33it/s]\u001b[A\n",
            "Iteration:  63% 57/91 [00:17<00:10,  3.33it/s]\u001b[A\n",
            "Iteration:  64% 58/91 [00:17<00:09,  3.33it/s]\u001b[A\n",
            "Iteration:  65% 59/91 [00:18<00:09,  3.33it/s]\u001b[A\n",
            "Iteration:  66% 60/91 [00:18<00:09,  3.33it/s]\u001b[A\n",
            "Iteration:  67% 61/91 [00:18<00:08,  3.34it/s]\u001b[A\n",
            "Iteration:  68% 62/91 [00:18<00:08,  3.33it/s]\u001b[A\n",
            "Iteration:  69% 63/91 [00:19<00:08,  3.34it/s]\u001b[A\n",
            "Iteration:  70% 64/91 [00:19<00:08,  3.34it/s]\u001b[A\n",
            "Iteration:  71% 65/91 [00:19<00:07,  3.35it/s]\u001b[A\n",
            "Iteration:  73% 66/91 [00:20<00:07,  3.35it/s]\u001b[A\n",
            "Iteration:  74% 67/91 [00:20<00:07,  3.34it/s]\u001b[A\n",
            "Iteration:  75% 68/91 [00:20<00:06,  3.35it/s]\u001b[A\n",
            "Iteration:  76% 69/91 [00:21<00:06,  3.36it/s]\u001b[A\n",
            "Iteration:  77% 70/91 [00:21<00:06,  3.37it/s]\u001b[A\n",
            "Iteration:  78% 71/91 [00:21<00:05,  3.38it/s]\u001b[A\n",
            "Iteration:  79% 72/91 [00:21<00:05,  3.36it/s]\u001b[A\n",
            "Iteration:  80% 73/91 [00:22<00:05,  3.36it/s]\u001b[A\n",
            "Iteration:  81% 74/91 [00:22<00:05,  3.37it/s]\u001b[A\n",
            "Iteration:  82% 75/91 [00:22<00:04,  3.38it/s]\u001b[A\n",
            "Iteration:  84% 76/91 [00:23<00:04,  3.37it/s]\u001b[A\n",
            "Iteration:  85% 77/91 [00:23<00:04,  3.37it/s]\u001b[A\n",
            "Iteration:  86% 78/91 [00:23<00:03,  3.35it/s]\u001b[A\n",
            "Iteration:  87% 79/91 [00:23<00:03,  3.34it/s]\u001b[A\n",
            "Iteration:  88% 80/91 [00:24<00:03,  3.34it/s]\u001b[A\n",
            "Iteration:  89% 81/91 [00:24<00:03,  3.32it/s]\u001b[A\n",
            "Iteration:  90% 82/91 [00:24<00:02,  3.33it/s]\u001b[A\n",
            "Iteration:  91% 83/91 [00:25<00:02,  3.33it/s]\u001b[A\n",
            "Iteration:  92% 84/91 [00:25<00:02,  3.33it/s]\u001b[A\n",
            "Iteration:  93% 85/91 [00:25<00:01,  3.33it/s]\u001b[A\n",
            "Iteration:  95% 86/91 [00:26<00:01,  3.34it/s]\u001b[A\n",
            "Iteration:  96% 87/91 [00:26<00:01,  3.34it/s]\u001b[A\n",
            "Iteration:  97% 88/91 [00:26<00:00,  3.30it/s]\u001b[A\n",
            "Iteration:  98% 89/91 [00:26<00:00,  3.32it/s]\u001b[A\n",
            "Iteration:  99% 90/91 [00:27<00:00,  3.33it/s]\u001b[A\n",
            "Iteration: 100% 91/91 [00:27<00:00,  3.32it/s]\n",
            "Epoch:  33% 1/3 [00:27<00:54, 27.41s/it]\n",
            "Iteration:   0% 0/91 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/91 [00:00<00:27,  3.32it/s]\u001b[A\n",
            "Iteration:   2% 2/91 [00:00<00:26,  3.32it/s]\u001b[A\n",
            "Iteration:   3% 3/91 [00:00<00:26,  3.33it/s]\u001b[A\n",
            "Iteration:   4% 4/91 [00:01<00:26,  3.34it/s]\u001b[A\n",
            "Iteration:   5% 5/91 [00:01<00:25,  3.34it/s]\u001b[A\n",
            "Iteration:   7% 6/91 [00:01<00:25,  3.34it/s]\u001b[A\n",
            "Iteration:   8% 7/91 [00:02<00:25,  3.34it/s]\u001b[A\n",
            "Iteration:   9% 8/91 [00:02<00:24,  3.34it/s]\u001b[A\n",
            "Iteration:  10% 9/91 [00:02<00:24,  3.34it/s]\u001b[A\n",
            "Iteration:  11% 10/91 [00:02<00:24,  3.34it/s]\u001b[A\n",
            "Iteration:  12% 11/91 [00:03<00:23,  3.36it/s]\u001b[A\n",
            "Iteration:  13% 12/91 [00:03<00:23,  3.37it/s]\u001b[A\n",
            "Iteration:  14% 13/91 [00:03<00:23,  3.37it/s]\u001b[A\n",
            "Iteration:  15% 14/91 [00:04<00:22,  3.38it/s]\u001b[A\n",
            "Iteration:  16% 15/91 [00:04<00:22,  3.37it/s]\u001b[A\n",
            "Iteration:  18% 16/91 [00:04<00:22,  3.37it/s]\u001b[A\n",
            "Iteration:  19% 17/91 [00:05<00:21,  3.37it/s]\u001b[A\n",
            "Iteration:  20% 18/91 [00:05<00:21,  3.36it/s]\u001b[A\n",
            "Iteration:  21% 19/91 [00:05<00:21,  3.36it/s]\u001b[A\n",
            "Iteration:  22% 20/91 [00:05<00:21,  3.34it/s]\u001b[A\n",
            "Iteration:  23% 21/91 [00:06<00:20,  3.34it/s]\u001b[A\n",
            "Iteration:  24% 22/91 [00:06<00:20,  3.34it/s]\u001b[A\n",
            "Iteration:  25% 23/91 [00:06<00:20,  3.33it/s]\u001b[A\n",
            "Iteration:  26% 24/91 [00:07<00:20,  3.33it/s]\u001b[A\n",
            "Iteration:  27% 25/91 [00:07<00:19,  3.33it/s]\u001b[A\n",
            "Iteration:  29% 26/91 [00:07<00:19,  3.32it/s]\u001b[A\n",
            "Iteration:  30% 27/91 [00:08<00:19,  3.32it/s]\u001b[A\n",
            "Iteration:  31% 28/91 [00:08<00:19,  3.31it/s]\u001b[A\n",
            "Iteration:  32% 29/91 [00:08<00:18,  3.32it/s]\u001b[A\n",
            "Iteration:  33% 30/91 [00:08<00:18,  3.32it/s]\u001b[A\n",
            "Iteration:  34% 31/91 [00:09<00:18,  3.32it/s]\u001b[A\n",
            "Iteration:  35% 32/91 [00:09<00:17,  3.31it/s]\u001b[A\n",
            "Iteration:  36% 33/91 [00:09<00:17,  3.32it/s]\u001b[A\n",
            "Iteration:  37% 34/91 [00:10<00:17,  3.33it/s]\u001b[A\n",
            "Iteration:  38% 35/91 [00:10<00:16,  3.34it/s]\u001b[A\n",
            "Iteration:  40% 36/91 [00:10<00:16,  3.34it/s]\u001b[A\n",
            "Iteration:  41% 37/91 [00:11<00:16,  3.34it/s]\u001b[A\n",
            "Iteration:  42% 38/91 [00:11<00:16,  3.31it/s]\u001b[A\n",
            "Iteration:  43% 39/91 [00:11<00:15,  3.31it/s]\u001b[A\n",
            "Iteration:  44% 40/91 [00:11<00:15,  3.32it/s]\u001b[A\n",
            "Iteration:  45% 41/91 [00:12<00:15,  3.32it/s]\u001b[A\n",
            "Iteration:  46% 42/91 [00:12<00:14,  3.32it/s]\u001b[A\n",
            "Iteration:  47% 43/91 [00:12<00:14,  3.33it/s]\u001b[A\n",
            "Iteration:  48% 44/91 [00:13<00:14,  3.33it/s]\u001b[A\n",
            "Iteration:  49% 45/91 [00:13<00:13,  3.34it/s]\u001b[A\n",
            "Iteration:  51% 46/91 [00:13<00:13,  3.35it/s]\u001b[A\n",
            "Iteration:  52% 47/91 [00:14<00:13,  3.35it/s]\u001b[A\n",
            "Iteration:  53% 48/91 [00:14<00:12,  3.37it/s]\u001b[A\n",
            "Iteration:  54% 49/91 [00:14<00:12,  3.35it/s]\u001b[A\n",
            "Iteration:  55% 50/91 [00:14<00:12,  3.36it/s]\u001b[A\n",
            "Iteration:  56% 51/91 [00:15<00:11,  3.38it/s]\u001b[A\n",
            "Iteration:  57% 52/91 [00:15<00:11,  3.38it/s]\u001b[A\n",
            "Iteration:  58% 53/91 [00:15<00:11,  3.39it/s]\u001b[A\n",
            "Iteration:  59% 54/91 [00:16<00:10,  3.39it/s]\u001b[A\n",
            "Iteration:  60% 55/91 [00:16<00:10,  3.33it/s]\u001b[A\n",
            "Iteration:  62% 56/91 [00:16<00:10,  3.34it/s]\u001b[A\n",
            "Iteration:  63% 57/91 [00:17<00:10,  3.35it/s]\u001b[A\n",
            "Iteration:  64% 58/91 [00:17<00:09,  3.32it/s]\u001b[A\n",
            "Iteration:  65% 59/91 [00:17<00:09,  3.34it/s]\u001b[A\n",
            "Iteration:  66% 60/91 [00:17<00:09,  3.34it/s]\u001b[A\n",
            "Iteration:  67% 61/91 [00:18<00:09,  3.33it/s]\u001b[A\n",
            "Iteration:  68% 62/91 [00:18<00:08,  3.33it/s]\u001b[A\n",
            "Iteration:  69% 63/91 [00:18<00:08,  3.33it/s]\u001b[A\n",
            "Iteration:  70% 64/91 [00:19<00:08,  3.30it/s]\u001b[A\n",
            "Iteration:  71% 65/91 [00:19<00:07,  3.32it/s]\u001b[A\n",
            "Iteration:  73% 66/91 [00:19<00:07,  3.29it/s]\u001b[A\n",
            "Iteration:  74% 67/91 [00:20<00:07,  3.31it/s]\u001b[A\n",
            "Iteration:  75% 68/91 [00:20<00:06,  3.32it/s]\u001b[A\n",
            "Iteration:  76% 69/91 [00:20<00:06,  3.33it/s]\u001b[A\n",
            "Iteration:  77% 70/91 [00:20<00:06,  3.33it/s]\u001b[A\n",
            "Iteration:  78% 71/91 [00:21<00:06,  3.33it/s]\u001b[A\n",
            "Iteration:  79% 72/91 [00:21<00:05,  3.34it/s]\u001b[A\n",
            "Iteration:  80% 73/91 [00:21<00:05,  3.33it/s]\u001b[A\n",
            "Iteration:  81% 74/91 [00:22<00:05,  3.33it/s]\u001b[A\n",
            "Iteration:  82% 75/91 [00:22<00:04,  3.33it/s]\u001b[A\n",
            "Iteration:  84% 76/91 [00:22<00:04,  3.33it/s]\u001b[A\n",
            "Iteration:  85% 77/91 [00:23<00:04,  3.33it/s]\u001b[A\n",
            "Iteration:  86% 78/91 [00:23<00:03,  3.31it/s]\u001b[A\n",
            "Iteration:  87% 79/91 [00:23<00:03,  3.31it/s]\u001b[A\n",
            "Iteration:  88% 80/91 [00:23<00:03,  3.33it/s]\u001b[A\n",
            "Iteration:  89% 81/91 [00:24<00:03,  3.33it/s]\u001b[A\n",
            "Iteration:  90% 82/91 [00:24<00:02,  3.33it/s]\u001b[A\n",
            "Iteration:  91% 83/91 [00:24<00:02,  3.31it/s]\u001b[A\n",
            "Iteration:  92% 84/91 [00:25<00:02,  3.31it/s]\u001b[A\n",
            "Iteration:  93% 85/91 [00:25<00:01,  3.31it/s]\u001b[A\n",
            "Iteration:  95% 86/91 [00:25<00:01,  3.32it/s]\u001b[A\n",
            "Iteration:  96% 87/91 [00:26<00:01,  3.33it/s]\u001b[A\n",
            "Iteration:  97% 88/91 [00:26<00:00,  3.33it/s]\u001b[A\n",
            "Iteration:  98% 89/91 [00:26<00:00,  3.33it/s]\u001b[A\n",
            "Iteration:  99% 90/91 [00:26<00:00,  3.32it/s]\u001b[A\n",
            "Iteration: 100% 91/91 [00:27<00:00,  3.36it/s]\n",
            "Epoch:  67% 2/3 [00:54<00:27, 27.31s/it]\n",
            "Iteration:   0% 0/91 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/91 [00:00<00:26,  3.40it/s]\u001b[A\n",
            "Iteration:   2% 2/91 [00:00<00:26,  3.38it/s]\u001b[A\n",
            "Iteration:   3% 3/91 [00:00<00:26,  3.37it/s]\u001b[A\n",
            "Iteration:   4% 4/91 [00:01<00:25,  3.36it/s]\u001b[A\n",
            "Iteration:   5% 5/91 [00:01<00:25,  3.34it/s]\u001b[A\n",
            "Iteration:   7% 6/91 [00:01<00:25,  3.33it/s]\u001b[A\n",
            "Iteration:   8% 7/91 [00:02<00:25,  3.32it/s]\u001b[A\n",
            "Iteration:   9% 8/91 [00:02<00:25,  3.30it/s]\u001b[A\n",
            "Iteration:  10% 9/91 [00:02<00:24,  3.31it/s]\u001b[A\n",
            "Iteration:  11% 10/91 [00:03<00:24,  3.32it/s]\u001b[A\n",
            "Iteration:  12% 11/91 [00:03<00:24,  3.31it/s]\u001b[A\n",
            "Iteration:  13% 12/91 [00:03<00:23,  3.32it/s]\u001b[A\n",
            "Iteration:  14% 13/91 [00:03<00:23,  3.32it/s]\u001b[A\n",
            "Iteration:  15% 14/91 [00:04<00:23,  3.32it/s]\u001b[A\n",
            "Iteration:  16% 15/91 [00:04<00:22,  3.31it/s]\u001b[A\n",
            "Iteration:  18% 16/91 [00:04<00:22,  3.32it/s]\u001b[A\n",
            "Iteration:  19% 17/91 [00:05<00:22,  3.31it/s]\u001b[A\n",
            "Iteration:  20% 18/91 [00:05<00:21,  3.32it/s]\u001b[A\n",
            "Iteration:  21% 19/91 [00:05<00:21,  3.32it/s]\u001b[A\n",
            "Iteration:  22% 20/91 [00:06<00:21,  3.33it/s]\u001b[A\n",
            "Iteration:  23% 21/91 [00:06<00:20,  3.33it/s]\u001b[A\n",
            "Iteration:  24% 22/91 [00:06<00:20,  3.33it/s]\u001b[A\n",
            "Iteration:  25% 23/91 [00:06<00:20,  3.30it/s]\u001b[A\n",
            "Iteration:  26% 24/91 [00:07<00:20,  3.30it/s]\u001b[A\n",
            "Iteration:  27% 25/91 [00:07<00:19,  3.31it/s]\u001b[A\n",
            "Iteration:  29% 26/91 [00:07<00:19,  3.30it/s]\u001b[A\n",
            "Iteration:  30% 27/91 [00:08<00:19,  3.31it/s]\u001b[A\n",
            "Iteration:  31% 28/91 [00:08<00:18,  3.33it/s]\u001b[A\n",
            "Iteration:  32% 29/91 [00:08<00:18,  3.33it/s]\u001b[A\n",
            "Iteration:  33% 30/91 [00:09<00:18,  3.33it/s]\u001b[A\n",
            "Iteration:  34% 31/91 [00:09<00:18,  3.33it/s]\u001b[A\n",
            "Iteration:  35% 32/91 [00:09<00:17,  3.33it/s]\u001b[A\n",
            "Iteration:  36% 33/91 [00:09<00:17,  3.33it/s]\u001b[A\n",
            "Iteration:  37% 34/91 [00:10<00:17,  3.33it/s]\u001b[A\n",
            "Iteration:  38% 35/91 [00:10<00:16,  3.32it/s]\u001b[A\n",
            "Iteration:  40% 36/91 [00:10<00:16,  3.33it/s]\u001b[A\n",
            "Iteration:  41% 37/91 [00:11<00:16,  3.32it/s]\u001b[A\n",
            "Iteration:  42% 38/91 [00:11<00:15,  3.32it/s]\u001b[A\n",
            "Iteration:  43% 39/91 [00:11<00:15,  3.32it/s]\u001b[A\n",
            "Iteration:  44% 40/91 [00:12<00:15,  3.29it/s]\u001b[A\n",
            "Iteration:  45% 41/91 [00:12<00:15,  3.29it/s]\u001b[A\n",
            "Iteration:  46% 42/91 [00:12<00:14,  3.31it/s]\u001b[A\n",
            "Iteration:  47% 43/91 [00:12<00:14,  3.32it/s]\u001b[A\n",
            "Iteration:  48% 44/91 [00:13<00:14,  3.32it/s]\u001b[A\n",
            "Iteration:  49% 45/91 [00:13<00:13,  3.33it/s]\u001b[A\n",
            "Iteration:  51% 46/91 [00:13<00:13,  3.32it/s]\u001b[A\n",
            "Iteration:  52% 47/91 [00:14<00:13,  3.33it/s]\u001b[A\n",
            "Iteration:  53% 48/91 [00:14<00:12,  3.33it/s]\u001b[A\n",
            "Iteration:  54% 49/91 [00:14<00:12,  3.34it/s]\u001b[A\n",
            "Iteration:  55% 50/91 [00:15<00:12,  3.33it/s]\u001b[A\n",
            "Iteration:  56% 51/91 [00:15<00:12,  3.33it/s]\u001b[A\n",
            "Iteration:  57% 52/91 [00:15<00:11,  3.32it/s]\u001b[A\n",
            "Iteration:  58% 53/91 [00:15<00:11,  3.32it/s]\u001b[A\n",
            "Iteration:  59% 54/91 [00:16<00:11,  3.32it/s]\u001b[A\n",
            "Iteration:  60% 55/91 [00:16<00:10,  3.33it/s]\u001b[A\n",
            "Iteration:  62% 56/91 [00:16<00:10,  3.33it/s]\u001b[A\n",
            "Iteration:  63% 57/91 [00:17<00:10,  3.33it/s]\u001b[A\n",
            "Iteration:  64% 58/91 [00:17<00:09,  3.33it/s]\u001b[A\n",
            "Iteration:  65% 59/91 [00:17<00:09,  3.33it/s]\u001b[A\n",
            "Iteration:  66% 60/91 [00:18<00:09,  3.34it/s]\u001b[A\n",
            "Iteration:  67% 61/91 [00:18<00:08,  3.34it/s]\u001b[A\n",
            "Iteration:  68% 62/91 [00:18<00:08,  3.31it/s]\u001b[A\n",
            "Iteration:  69% 63/91 [00:18<00:08,  3.32it/s]\u001b[A\n",
            "Iteration:  70% 64/91 [00:19<00:08,  3.32it/s]\u001b[A\n",
            "Iteration:  71% 65/91 [00:19<00:07,  3.32it/s]\u001b[A\n",
            "Iteration:  73% 66/91 [00:19<00:07,  3.32it/s]\u001b[A\n",
            "Iteration:  74% 67/91 [00:20<00:07,  3.32it/s]\u001b[A\n",
            "Iteration:  75% 68/91 [00:20<00:06,  3.31it/s]\u001b[A\n",
            "Iteration:  76% 69/91 [00:20<00:06,  3.32it/s]\u001b[A\n",
            "Iteration:  77% 70/91 [00:21<00:06,  3.33it/s]\u001b[A\n",
            "Iteration:  78% 71/91 [00:21<00:06,  3.33it/s]\u001b[A\n",
            "Iteration:  79% 72/91 [00:21<00:05,  3.33it/s]\u001b[A\n",
            "Iteration:  80% 73/91 [00:21<00:05,  3.34it/s]\u001b[A\n",
            "Iteration:  81% 74/91 [00:22<00:05,  3.34it/s]\u001b[A\n",
            "Iteration:  82% 75/91 [00:22<00:04,  3.35it/s]\u001b[A\n",
            "Iteration:  84% 76/91 [00:22<00:04,  3.35it/s]\u001b[A\n",
            "Iteration:  85% 77/91 [00:23<00:04,  3.36it/s]\u001b[A\n",
            "Iteration:  86% 78/91 [00:23<00:03,  3.37it/s]\u001b[A\n",
            "Iteration:  87% 79/91 [00:23<00:03,  3.37it/s]\u001b[A\n",
            "Iteration:  88% 80/91 [00:24<00:03,  3.38it/s]\u001b[A\n",
            "Iteration:  89% 81/91 [00:24<00:02,  3.38it/s]\u001b[A\n",
            "Iteration:  90% 82/91 [00:24<00:02,  3.38it/s]\u001b[A\n",
            "Iteration:  91% 83/91 [00:24<00:02,  3.38it/s]\u001b[A\n",
            "Iteration:  92% 84/91 [00:25<00:02,  3.38it/s]\u001b[A\n",
            "Iteration:  93% 85/91 [00:25<00:01,  3.37it/s]\u001b[A\n",
            "Iteration:  95% 86/91 [00:25<00:01,  3.36it/s]\u001b[A\n",
            "Iteration:  96% 87/91 [00:26<00:01,  3.35it/s]\u001b[A\n",
            "Iteration:  97% 88/91 [00:26<00:00,  3.35it/s]\u001b[A\n",
            "Iteration:  98% 89/91 [00:26<00:00,  3.34it/s]\u001b[A\n",
            "Iteration:  99% 90/91 [00:27<00:00,  3.33it/s]\u001b[A\n",
            "Iteration: 100% 91/91 [00:27<00:00,  3.35it/s]\n",
            "Epoch: 100% 3/3 [01:21<00:00, 27.21s/it]\n",
            "04/24/2020 13:18:49 - INFO - transformers.trainer -   \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "04/24/2020 13:18:49 - INFO - transformers.trainer -   Saving model checkpoint to output\n",
            "04/24/2020 13:18:49 - INFO - transformers.configuration_utils -   Configuration saved in output/config.json\n",
            "04/24/2020 13:18:50 - INFO - transformers.modeling_utils -   Model weights saved in output/pytorch_model.bin\n",
            "04/24/2020 13:18:50 - INFO - __main__ -   *** Evaluate ***\n",
            "04/24/2020 13:18:50 - INFO - transformers.trainer -   ***** Running Evaluation *****\n",
            "04/24/2020 13:18:50 - INFO - transformers.trainer -     Num examples = 82\n",
            "04/24/2020 13:18:50 - INFO - transformers.trainer -     Batch size = 8\n",
            "Evaluation: 100% 11/11 [00:01<00:00,  5.95it/s]\n",
            "04/24/2020 13:18:52 - INFO - __main__ -   ***** Eval results *****\n",
            "04/24/2020 13:18:52 - INFO - __main__ -     perplexity = 5.31026133899204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36bn7FyyMHoh",
        "colab_type": "code",
        "outputId": "97fc414d-bcf8-4d88-d695-a18f3a593e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install fitz\n",
        "!pip install PyMuPDF\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fitz\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/28/27f27d66eb82f24e6595deb26c0a875e62431878c416e38eac515023abb2/fitz-0.0.1.dev2-py2.py3-none-any.whl\n",
            "Collecting configobj\n",
            "  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fitz) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fitz) (1.18.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fitz) (1.0.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (from fitz) (3.0.2)\n",
            "Collecting configparser\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Collecting nipype\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/f2/e094bf653b5ec180f8227901056ff35ffd7edfc23f967b67dd4238d0f4c7/nipype-1.4.2-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 24.0MB/s \n",
            "\u001b[?25hCollecting pyxnat\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/0e/5110817d032aa1d32bbc6278e2add99d3538c5bd0716a921088fcee851c5/pyxnat-1.2.1.0.post3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: httplib2 in /usr/local/lib/python3.6/dist-packages (from fitz) (0.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from configobj->fitz) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fitz) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fitz) (2.8.1)\n",
            "Collecting simplejson>=3.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/a7b98aa9256c8843f92878966dc3d8d914c14aad97e2c5ce4798d5743e07/simplejson-3.17.0.tar.gz (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.5MB/s \n",
            "\u001b[?25hCollecting traits!=5.0,>=4.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/af/c6dc88130106d69e4f9a192043c85ed4cb522f83b9041b8691f0b0678405/traits-6.0.0.tar.gz (441kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 56.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from nipype->fitz) (3.0.12)\n",
            "Requirement already satisfied: networkx>=1.9 in /usr/local/lib/python3.6/dist-packages (from nipype->fitz) (2.4)\n",
            "Collecting prov>=1.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/f1/85f277cf15ce2fed6f189b220ff14d7b33b21cc7beb95ae48f1255672e74/prov-1.5.3-py2.py3-none-any.whl (423kB)\n",
            "\u001b[K     |████████████████████████████████| 430kB 57.7MB/s \n",
            "\u001b[?25hCollecting etelemetry\n",
            "  Downloading https://files.pythonhosted.org/packages/50/fe/7b4a4d7bd2756884ba2af5445ac538bff20ca8e6c89e24b253cc51845f1b/etelemetry-0.2.1-py3-none-any.whl\n",
            "Collecting neurdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/66/304a1ad40fecee3504a315d831afcaebe156a62ff1628311bac3cb8d55c8/neurdflib-5.0.1-py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.6/dist-packages (from nipype->fitz) (7.1.1)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.6/dist-packages (from nipype->fitz) (1.3.0)\n",
            "Requirement already satisfied: pydotplus in /usr/local/lib/python3.6/dist-packages (from nipype->fitz) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from nipype->fitz) (20.3)\n",
            "Collecting lxml>=4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/ba/a0e6866057fc0bbd17192925c1d63a3b85cf522965de9bc02364d08e5b84/lxml-4.5.0-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8MB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from pyxnat->fitz) (2.21.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.9->nipype->fitz) (4.4.2)\n",
            "Collecting rdflib>=4.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 59.0MB/s \n",
            "\u001b[?25hCollecting ci-info>=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/cf/01/664a10490000d7154fa71358af87681696b8116a12d869a267063c470fbc/ci_info-0.2.0-py3-none-any.whl\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from neurdflib->nipype->fitz) (2.4.7)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->pyxnat->fitz) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->pyxnat->fitz) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->pyxnat->fitz) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->pyxnat->fitz) (2.8)\n",
            "Building wheels for collected packages: configobj, pyxnat, simplejson, traits\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34546 sha256=4939c333c9d7b1bf607363d79db53dae2a72a6955fb11c61546a237c1709253c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n",
            "  Building wheel for pyxnat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyxnat: filename=pyxnat-1.2.1.0.post3-cp36-none-any.whl size=71623 sha256=2d7077bfe0fc72eb748e53307d2579ce1c8976e2a04a1d2780ce21948f0189be\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/46/71/7096c8f1537087e7628bdcc723f6e766880f8dde2667009371\n",
            "  Building wheel for simplejson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for simplejson: filename=simplejson-3.17.0-cp36-cp36m-linux_x86_64.whl size=114200 sha256=0ad593ca077794ffdf172413bc7bb46931b8f304703370115e353b0b3a4e0b20\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/c0/83/dcd0339abb2640544bb8e0938aab2d069cef55e5647ce6e097\n",
            "  Building wheel for traits (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for traits: filename=traits-6.0.0-cp36-cp36m-linux_x86_64.whl size=385403 sha256=7a20dd2ec79e815614f84e69ed5130fa44807042a6792800b89e0dd72937b4f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/a7/f0/d1dfae8d3a4e5638a40818830c741c1c0e9f8a590b9ea22935\n",
            "Successfully built configobj pyxnat simplejson traits\n",
            "Installing collected packages: configobj, configparser, simplejson, traits, lxml, isodate, rdflib, prov, ci-info, etelemetry, neurdflib, nipype, pyxnat, fitz\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed ci-info-0.2.0 configobj-5.0.6 configparser-5.0.0 etelemetry-0.2.1 fitz-0.0.1.dev2 isodate-0.6.0 lxml-4.5.0 neurdflib-5.0.1 nipype-1.4.2 prov-1.5.3 pyxnat-1.2.1.0.post3 rdflib-5.0.0 simplejson-3.17.0 traits-6.0.0\n",
            "Collecting PyMuPDF\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/5c/a43e9bd5c182b6125c301504f711e603cc8beb57ccbaad32caea82135e6d/PyMuPDF-1.16.18-cp36-cp36m-manylinux2010_x86_64.whl (5.7MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7MB 6.4MB/s \n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.16.18\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 8.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 20.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 57.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 53.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=a50d9fd35d9c8be06cc5638327a7c921b00a2f49d1df5b0025a91e363bf6e0b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmZaY_sgMNMe",
        "colab_type": "code",
        "outputId": "be4ed395-11ff-4d5a-e973-927db1e11aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import fitz\n",
        "\n",
        "#ROOT = \"/content/drive/My Drive/Capstone/\"\n",
        "doc = fitz.open(\"Cloud Computing Bible.pdf\")\n",
        "page = doc.loadPage(27)\n",
        "dataset = page.getText()\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xxvi\\nIntroduction\\nl The cloud will enable new social services by connecting users via social networks that are \\nconstructed using multiple cloud services.\\nl New applications will be easier to create and will be based on standard modular parts.\\nl It will lessen the role that proprietary operating systems have in our daily computing.\\nl You will be connected through the cloud wherever you are and at all times.\\nFrankly, it is hard to predict what new capabilities the cloud may enable. The cloud has a trajec-\\ntory that is hard to plot and a scope that reaches into so many aspects of our daily life that innova-\\ntion can occur across a broad range.\\nMany technologically savvy people have told me they don’t understand what the fuss about cloud \\ncomputing is; in fact, they believe there is nothing new about cloud computing, at least from a \\ntechnological standpoint. Indeed, they have a point. The technologies that enable cloud comput-\\ning—system and resource virtualization, thin clients (browsers, for example), virtual private net-\\nworks and tunneling, and others—are all technologies that existed before anyone ever began to \\ntalk about cloud computing. That is all true. Cloud computing is a revolutionary way of architect-\\ning and implementing services based on evolutionary changes. Cloud Computing Bible attempts to \\nexplain how this all came about.\\nHow to Read This Book\\nCloud Computing Bible is made up of 21 chapters in five parts. To read this book and get the most \\nout of it, you should know about basic computer operations and theory. You should be able to \\nturn a computer on and know what operating system is running, how processing and input/output \\nis used, and be able to connect with a browser to different Web sites. You should understand the \\nbasic user interface elements used by many browsers, such as Microsoft Internet Explorer, Mozilla \\nFirefox, Apple Safari, or Google Chrome.\\nThese are basic skills without which it would be hard to effectively maximize the value contained \\nin this book. If you don’t have these skills, Wiley publishes a number of introductory computer \\nbooks that will give them to you.\\nIt doesn’t matter which type of computer operating system you use because most of cloud computing \\nis operating-system-neutral. Indeed, as time goes by, it may not matter whether you use a computer \\nat all. Mobile devices such as smartphones and tablets are on their way to displacing computers in \\nmany venues. If you have some familiarity with smartphones, that would be helpful in understanding \\nthe last part of this book on mobile-based cloud applications, but it isn’t a necessity.\\nPart I of the book, called “Examining the Value Proposition,” defines what cloud computing is and \\nwhy you should be interested in it. This vocabulary, along with description of cloud architectures \\n03_9780470903568-flast.indd   xxvi\\n03_9780470903568-flast.indd   xxvi\\n12/1/10   10:56 PM\\n12/1/10   10:56 PM\\nwww.it-ebooks.info\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyl83hhDMokN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = \"\"\n",
        "for i in range(26, 410):\n",
        "  page = doc.loadPage(i)\n",
        "  train_data += page.getText()\n",
        "\n",
        "test_data = \"\"\n",
        "for i in range(410, 496):\n",
        "  page = doc.loadPage(i)\n",
        "  test_data += page.getText()\n",
        "\n",
        "f = open(\"train_data.raw\", \"w\")\n",
        "f.write(train_data)\n",
        "f.close()\n",
        "\n",
        "f = open(\"test_data.raw\", \"w\")\n",
        "f.write(test_data)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10OFiPZzOI33",
        "colab_type": "code",
        "outputId": "2b8eb28c-c0c5-4f92-f715-fb7312344938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(train_data))\n",
        "len(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "819195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180105"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PDedQDqOrXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx6nT2-CWOYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = \"Amazon Cloudfront\"\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "input_ids = torch.tensor(tokenizer.encode(words)).unsqueeze(0)  # Batch size 1\n",
        "outputs = model(input_ids)\n",
        "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT6iEm9fWRBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = {}\n",
        "for key in concepts:\n",
        "  input_ids = torch.tensor(tokenizer.encode(key)).unsqueeze(0)  # Batch size 1\n",
        "  outputs = model(input_ids)\n",
        "  last_hidden_states = outputs[0]\n",
        "  embeddings[key] = last_hidden_states[0][0].detach().numpy() #Get CLS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThhIGdTZWYmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT = \"/content/drive/My Drive/Capstone/\"\n",
        "!cp -r output/pytorch_model.bin ROOT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq9aL8WWjYoV",
        "colab_type": "code",
        "outputId": "66d2687a-1e1d-4690-8091-8601df477546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls output/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config.json  eval_results_lm.txt  pytorch_model.bin  training_args.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ3ujyzSWY2l",
        "colab_type": "code",
        "outputId": "2e46e33d-a0a9-41d0-bf50-5c437946afd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}