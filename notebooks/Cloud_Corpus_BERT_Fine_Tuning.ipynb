{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cloud Corpus BERT Fine Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVbSKwoiUNg8",
        "colab_type": "code",
        "outputId": "597b166c-9c5e-4c40-d157-d39167e54805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install fitz\n",
        "!pip install PyMuPDF\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fitz\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/28/27f27d66eb82f24e6595deb26c0a875e62431878c416e38eac515023abb2/fitz-0.0.1.dev2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fitz) (1.18.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fitz) (1.0.3)\n",
            "Collecting pyxnat\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/0e/5110817d032aa1d32bbc6278e2add99d3538c5bd0716a921088fcee851c5/pyxnat-1.2.1.0.post3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.1MB/s \n",
            "\u001b[?25hCollecting nipype\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/f2/e094bf653b5ec180f8227901056ff35ffd7edfc23f967b67dd4238d0f4c7/nipype-1.4.2-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: httplib2 in /usr/local/lib/python3.6/dist-packages (from fitz) (0.17.2)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (from fitz) (3.0.2)\n",
            "Collecting configparser\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fitz) (1.4.1)\n",
            "Collecting configobj\n",
            "  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fitz) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fitz) (2018.9)\n",
            "Collecting lxml>=4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/ba/a0e6866057fc0bbd17192925c1d63a3b85cf522965de9bc02364d08e5b84/lxml-4.5.0-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8MB 40.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from pyxnat->fitz) (2.21.0)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.6/dist-packages (from nipype->fitz) (7.1.1)\n",
            "Collecting prov>=1.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/f1/85f277cf15ce2fed6f189b220ff14d7b33b21cc7beb95ae48f1255672e74/prov-1.5.3-py2.py3-none-any.whl (423kB)\n",
            "\u001b[K     |████████████████████████████████| 430kB 44.3MB/s \n",
            "\u001b[?25hCollecting neurdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/66/304a1ad40fecee3504a315d831afcaebe156a62ff1628311bac3cb8d55c8/neurdflib-5.0.1-py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from nipype->fitz) (3.0.12)\n",
            "Collecting etelemetry\n",
            "  Downloading https://files.pythonhosted.org/packages/50/fe/7b4a4d7bd2756884ba2af5445ac538bff20ca8e6c89e24b253cc51845f1b/etelemetry-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.6/dist-packages (from nipype->fitz) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from nipype->fitz) (20.3)\n",
            "Requirement already satisfied: networkx>=1.9 in /usr/local/lib/python3.6/dist-packages (from nipype->fitz) (2.4)\n",
            "Requirement already satisfied: pydotplus in /usr/local/lib/python3.6/dist-packages (from nipype->fitz) (2.0.2)\n",
            "Collecting traits!=5.0,>=4.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/af/c6dc88130106d69e4f9a192043c85ed4cb522f83b9041b8691f0b0678405/traits-6.0.0.tar.gz (441kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 45.0MB/s \n",
            "\u001b[?25hCollecting simplejson>=3.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/a7b98aa9256c8843f92878966dc3d8d914c14aad97e2c5ce4798d5743e07/simplejson-3.17.0.tar.gz (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from configobj->fitz) (1.12.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->pyxnat->fitz) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->pyxnat->fitz) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->pyxnat->fitz) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->pyxnat->fitz) (2.8)\n",
            "Collecting rdflib>=4.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from neurdflib->nipype->fitz) (2.4.7)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hCollecting ci-info>=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/cf/01/664a10490000d7154fa71358af87681696b8116a12d869a267063c470fbc/ci_info-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.9->nipype->fitz) (4.4.2)\n",
            "Building wheels for collected packages: pyxnat, configobj, traits, simplejson\n",
            "  Building wheel for pyxnat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyxnat: filename=pyxnat-1.2.1.0.post3-cp36-none-any.whl size=71623 sha256=e0e00f5f368769aedb29e439da0e3a59b5f016eae7b08f20455420db897a60b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/46/71/7096c8f1537087e7628bdcc723f6e766880f8dde2667009371\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34546 sha256=c709a59a0c7c2eff9b8bb3751391d0a974fcd1ea4387ec4aa29e25fcad00c4f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n",
            "  Building wheel for traits (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for traits: filename=traits-6.0.0-cp36-cp36m-linux_x86_64.whl size=385411 sha256=e84e48af08e6cc4d8271eeb12314918aa33c8121cda6c28e7444502fcac1ac4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/a7/f0/d1dfae8d3a4e5638a40818830c741c1c0e9f8a590b9ea22935\n",
            "  Building wheel for simplejson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for simplejson: filename=simplejson-3.17.0-cp36-cp36m-linux_x86_64.whl size=114208 sha256=dcfbbb045adc7647ab93df4c965ed56ced3ddd87f2125c8dbecd1b51a249b2b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/c0/83/dcd0339abb2640544bb8e0938aab2d069cef55e5647ce6e097\n",
            "Successfully built pyxnat configobj traits simplejson\n",
            "Installing collected packages: lxml, pyxnat, isodate, rdflib, prov, neurdflib, ci-info, etelemetry, traits, simplejson, nipype, configparser, configobj, fitz\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed ci-info-0.2.0 configobj-5.0.6 configparser-5.0.0 etelemetry-0.2.1 fitz-0.0.1.dev2 isodate-0.6.0 lxml-4.5.0 neurdflib-5.0.1 nipype-1.4.2 prov-1.5.3 pyxnat-1.2.1.0.post3 rdflib-5.0.0 simplejson-3.17.0 traits-6.0.0\n",
            "Collecting PyMuPDF\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/5c/a43e9bd5c182b6125c301504f711e603cc8beb57ccbaad32caea82135e6d/PyMuPDF-1.16.18-cp36-cp36m-manylinux2010_x86_64.whl (5.7MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7MB 2.6MB/s \n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.16.18\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 12.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 15.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 25.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.40)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.40)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=c9c370c3e353cb54ad1e134c09d15c298f2ddc7f8db3adb05d574ba6e038a40b\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHh0Ah1XTsex",
        "colab_type": "code",
        "outputId": "66098b05-ca35-4a60-f98b-9fec34a37db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.rnn as rnn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import fitz\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DEVICE"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzrwdolI2Qp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT = \"/content/drive/My Drive/Capstone/\"\n",
        "doc = fitz.open(ROOT + \"Cloud Computing Bible.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dExOUf91kqxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page = doc.loadPage(27)\n",
        "dataset = page.getText()\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSqsavBCUG57",
        "colab_type": "code",
        "outputId": "5e0d18e3-0bde-4564-bd1b-e82366a2da31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "import nltk.data\n",
        "\n",
        "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "print(len(sent_tokenizer.tokenize(dataset)))\n",
        "for sentence in sent_tokenizer.tokenize(dataset):\n",
        "  print(len(sentence))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n",
            "154\n",
            "88\n",
            "89\n",
            "76\n",
            "74\n",
            "163\n",
            "218\n",
            "26\n",
            "264\n",
            "17\n",
            "113\n",
            "67\n",
            "84\n",
            "106\n",
            "188\n",
            "166\n",
            "112\n",
            "116\n",
            "127\n",
            "78\n",
            "104\n",
            "175\n",
            "134\n",
            "190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlpGuP71XB8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data, sent_tokenizer, bert_tokenizer):\n",
        "        sentences = sent_tokenizer.tokenize(data)\n",
        "\n",
        "        sentence_tokens = []\n",
        "        for sentence in sentences:\n",
        "          tokens = torch.tensor(tokenizer.encode(sentence,max_length=25, pad_to_max_length=True, add_special_tokens=True))\n",
        "          sentence_tokens.append(tokens.unsqueeze(0))\n",
        "          #print(sentence)\n",
        "          #print(tokenizer.tokenize(sentence))\n",
        "          #print(len(tokenizer.tokenize(sentence)))\n",
        "          #print(tokens)\n",
        "          #print(len(tokens))\n",
        "          #print(\"\\n\")\n",
        "        \n",
        "        self.data = torch.cat(sentence_tokens,dim=0)\n",
        "        print(self.data.shape)\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "        txt = self.data[i]\n",
        "        \n",
        "        return txt[:-1],txt[1:]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.data.size(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfZDoTSTlkpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self,vocab_size,embed_size,hidden_size, nlayers):\n",
        "        super(ModelLanguageModel,self).__init__()\n",
        "        self.vocab_size=vocab_size\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.nlayers=nlayers\n",
        "\n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
        "        self.rnn = nn.LSTM(input_size = embed_size,hidden_size=hidden_size,num_layers=nlayers)\n",
        "        \n",
        "        self.scoring = nn.Linear(hidden_size,vocab_size)\n",
        "        \n",
        "    def forward(self,seq_batch, attn_masks): # N x L\n",
        "\n",
        "        embed = self.bert_layer(seq_batch, attention_mask = attn_masks)\n",
        "        print(embed.shape)\n",
        "\n",
        "        embed = embed[0][:, 1:]\n",
        "\n",
        "        #embed = self.embedding(seq_batch) #L x N x E\n",
        "        hidden = None\n",
        "        embed = embed.permute(1, 0, 2)\n",
        "        output_lstm,hidden = self.rnn(embed,hidden) #L x N x H\n",
        "        output_lstm_flatten = output_lstm.view(-1,self.hidden_size) #(L*N) x H\n",
        "        output_flatten = self.scoring(output_lstm_flatten) #(L*N) x V\n",
        "\n",
        "        batch_size = seq_batch.size(1)\n",
        "        return output_flatten.view(-1,batch_size,self.vocab_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A5d-NdXku9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, optimizer, train_loader, val_loader):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    criterion = criterion.to(DEVICE)\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (inputs,targets) in enumerate(train_loader):\n",
        "\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        attn_masks = (inputs != 0).long()\n",
        "        targets = targets.to(DEVICE).permute(1,0)\n",
        "        outputs = model(inputs, attn_masks)\n",
        "        \n",
        "        loss = criterion(outputs.view(-1,outputs.size(2)),targets.view(-1))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #if batch_idx % 50 == 0 and batch_idx != 0:\n",
        "        print(\"batch_idx: \" + str(batch_idx) + \", loss: \" + str(loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hAPu8vilsNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ModelLanguageModel(charcount,256,256,3)\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001, weight_decay=1e-6)\n",
        "\n",
        "import nltk.data\n",
        "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "train_dataset = ModelDataset(dataset, sent_tokenizer, bert_tokenizer)\n",
        "#val_dataset = ModelDataset(shakespeare_array[split:])\n",
        "train_loader = DataLoader(train_dataset, shuffle=False, batch_size=2)\n",
        "#val_loader = DataLoader(val_dataset, shuffle=False, batch_size=64, collate_fn = collate, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYuJMI88llj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(10):\n",
        "    train_epoch(model, optimizer, train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}